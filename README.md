# D√©tection de Nuages Martiens par Random Forest
## Projet de R√©f√©rence (Baseline) pour la Classification de Profils Atmosph√©riques (MCS)

![Badge Python](https://img.shields.io/badge/Python-3.9%2B-blue.svg)
![Badge Scikit-learn](https://img.shields.io/badge/Scikit--learn-1.x-orange.svg)
![Badge Statut](https://img.shields.io/badge/Statut-Baseline%20Compl√©t√©e-brightgreen.svg)
Ce projet vise √† construire un mod√®le de **baseline** (r√©f√©rence) pour la d√©tection automatique des nuages de haute altitude sur Mars, en utilisant les donn√©es de l'instrument MCS (Mars Climate Sounder).

L'objectif n'est pas d'atteindre la perfection, mais de :
1.  Prouver qu'une d√©tection automatique via le Machine Learning classique est possible.
2.  √âtablir un score de performance (ex: Pr√©cision, F1-Score) que des mod√®les plus complexes (Deep Learning) devront battre.
3.  Comprendre quelles caract√©ristiques physiques sont les plus importantes pour pr√©dire un nuage.

---

### 1. L'Hypoth√®se Scientifique üî≠

Les nuages de haute altitude sur Mars (les "arches") ne sont pas al√©atoires. Ils cr√©ent des **signatures statistiques identifiables** dans les profils verticaux de temp√©rature, d'opacit√© de la poussi√®re et d'opacit√© de la glace d'eau.

Ce projet postule qu'un mod√®le de **Random Forest** peut √™tre entra√Æn√© √† reconna√Ætre ces signatures, √† condition qu'on lui fournisse des caract√©ristiques (features) pertinentes.

### 2. La T√¢che de Machine Learning ü§ñ

* **Type :** Classification Binaire Supervis√©e.
* **Input (X) :** Un vecteur de caract√©ristiques *cr√©√©es manuellement* (Feature Engineering) d√©crivant chaque profil atmosph√©rique.
* **Output (Y) :** Une pr√©diction √† 2 classes : `0` (Pas de Nuage) ou `1` (Nuage Pr√©sent).
* **V√©rit√© Terrain :** Les classifications consensus issues du projet Zooniverse "Cloudspotting on Mars".

### 3. La M√©thodologie üß†

Le c≈ìur de ce projet est le **Feature Engineering**. Un Random Forest ne peut pas interpr√©ter une s√©quence brute ou "voir" une forme (une "arche"). Notre travail consiste √† traduire la *physique* et la *morphologie* de chaque profil en un ensemble de nombres.

**1. Feature Engineering (Cr√©ation de Caract√©ristiques)**
Le script `notebooks/02_feature_engineering.ipynb` transforme chaque profil vertical brut en une seule ligne d'un tableur, avec des colonnes descriptives.
Exemples de features cr√©√©es :
* `temp_min_absolue` : La temp√©rature la plus basse du profil.
* `altitude_de_temp_min` : L'altitude de cette temp√©rature minimale.
* `pic_opacite_glace` : La valeur maximale d'opacit√© de la glace.
* `altitude_pic_glace` : L'altitude de ce pic de glace.
* `temp_moyenne_70_80km` : La temp√©rature moyenne dans la "zone d'int√©r√™t".
* `pente_temp_max` : La pente la plus raide (positive ou n√©gative) de la courbe de temp√©rature.
* ... et bien d'autres.

**2. Mod√©lisation (Baseline)**
Le script `notebooks/03_model_baseline.ipynb` utilise le tableur de features pour entra√Æner le mod√®le.
* **Mod√®le :** `RandomForestClassifier` (Scikit-learn).
* **Pourquoi ?** Il est robuste, performant sur les donn√©es tabulaires et **interpr√©table** (il peut nous dire quelles features ont √©t√© les plus utiles).
* **Pipeline :** Une `Pipeline` Scikit-learn est utilis√©e pour inclure le `StandardScaler` (mise √† l'√©chelle) et le mod√®le, garantissant la reproductibilit√© et √©vitant les fuites de donn√©es.

---

### 4. üìà R√©sultats de la Baseline

*(Section √† compl√©ter par vous-m√™me)*

Le mod√®le de r√©f√©rence (Random Forest) a √©t√© entra√Æn√© sur 80% des donn√©es et test√© sur les 20% restants.

#### M√©triques de Performance

| M√©trique | Score (Test Set) |
| :--- | :--- |
| Pr√©cision (Accuracy) | **XX.X%** |
| F1-Score (Macro) | **XX.X%** |
| Rappel (Recall - Classe 1) | **XX.X%** |
| Pr√©cision (Precision - Classe 1) | **XX.X%** |

#### Matrice de Confusion

*(Ins√©rez ici votre image de la matrice de confusion)*
`![Matrice de Confusion](reports/figures/confusion_matrix.png)`

#### Importance des Caract√©ristiques (Feature Importances)

Cette analyse est cruciale pour valider notre hypoth√®se. Elle montre quelles caract√©ristiques le mod√®le a le plus utilis√©es pour prendre ses d√©cisions.

*(Ins√©rez ici votre graphique des feature importances)*
`![Feature Importances](reports/figures/feature_importances.png)`

**Principales d√©couvertes :**
1.  La caract√©ristique la plus importante √©tait `[NOM_DE_LA_FEATURE_1]` (ex: `pic_opacite_glace`).
2.  L'altitude du pic (`[NOM_DE_LA_FEATURE_2]`) √©tait √©galement un pr√©dicteur cl√©.
3.  ...

---

### 5. üöÄ Comment Reproduire le Projet

1.  **Cloner le d√©p√¥t :**
    ```bash
    git clone [https://github.com/](https://github.com/)[VOTRE_NOM]/projet-mars-clouds-rf.git
    cd projet-mars-clouds-rf
    ```

2.  **Cr√©er un environnement virtuel et l'activer :**
    ```bash
    python -m venv venv
    source venv/bin/activate  # Sur Windows: venv\Scripts\activate
    ```

3.  **Installer les d√©pendances :**
    ```bash
    pip install -r requirements.txt
    ```

4.  **Ajouter les donn√©es (Important !) :**
    Les donn√©es ne sont pas suivies par Git (voir `.gitignore`). Vous devez placer vos fichiers de donn√©es brutes (issus de Zooniverse) dans le dossier `data/raw/`.

5.  **Ex√©cuter les Notebooks :**
    Lancez Jupyter Lab (`jupyter lab`) et suivez les notebooks dans l'ordre num√©rique dans le dossier `notebooks/`:
    * `01_data_exploration.ipynb` : Analyse exploratoire des profils bruts.
    * `02_feature_engineering.ipynb` : G√©n√©ration du fichier `data/processed/features.csv`.
    * `03_model_baseline.ipynb` : Entra√Ænement, √©valuation du mod√®le et g√©n√©ration des graphiques de r√©sultats.

### 6. üìÇ Structure du D√©p√¥t

```text
projet-mars-clouds-rf/
|
+-- .gitignore          # Fichiers et dossiers √† ignorer par Git
+-- README.md           # Ce fichier
+-- requirements.txt    # D√©pendances Python
|
+-- data/               # (Ignor√© par Git) Donn√©es du projet
|   +-- raw/            # Donn√©es brutes (√† placer ici)
|   \-- processed/      # Donn√©es nettoy√©es (ex: features.csv)
|
+-- notebooks/          # Carnets Jupyter pour l'analyse
|   +-- 01_data_exploration.ipynb
|   +-- 02_feature_engineering.ipynb
|   \-- 03_model_baseline.ipynb
|
+-- src/                # (Optionnel) Scripts ou modules Python
|   \-- feature_utils.py # Ex: Fonctions d'aide pour le feature engineering
|
+-- models/             # (Ignor√© par Git) Mod√®les entra√Æn√©s
|   \-- rf_baseline_pipeline.joblib
|
\-- reports/            # (Non ignor√©) Figures et rapports
    \-- figures/
        +-- confusion_matrix.png     \-- feature_importances.png  ```

---

### 7. üéØ Prochaines √âtapes

* [ ] Am√©liorer le feature engineering avec des caract√©ristiques plus complexes (ex: largeurs de pic, int√©grales).
* [ ] Tester d'autres mod√®les de ML classiques (ex: XGBoost, LightGBM) pour voir s'ils battent le RF.
* [ ] Utiliser cette baseline comme r√©f√©rence pour un mod√®le de **Deep Learning** (ex: CNN 1D) qui analysera directement les profils bruts.